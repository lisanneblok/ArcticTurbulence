{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# gsw oceanic toolbox: http://www.teos-10.org/pubs/Getting_Started.pdf\n",
    "import gsw\n",
    "from scipy.io import loadmat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "from src.features.processing_func import mld, seasonal_sin\n",
    "from src.features.calc_seaice import calc_SIC\n",
    "from src.utils.directories import get_parent_directory\n",
    "from src.features.feature_generation import processing_functions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = get_parent_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mix = os.path.join(parent_dir, \"data/interim/arctic_mix.nc\")\n",
    "asbo_nc = os.path.join(parent_dir, \"data/interim/ASBO-TEACOSI_ds.nc\")\n",
    "mosaic_nc = os.path.join(parent_dir, \"data/interim/mosaic_ds.nc\")\n",
    "nice_nc = os.path.join(parent_dir, \"data/interim/nice_ds.nc\")\n",
    "HM_nc = os.path.join(parent_dir, \"data/interim/HM_ds.nc\")\n",
    "barneo2007_nc = os.path.join(parent_dir, \"data/interim/barneo2007_ds.nc\")\n",
    "barneo2008_nc = os.path.join(parent_dir, \"data/interim/barneo2008_ds.nc\")\n",
    "KB2018616_nc = os.path.join(parent_dir, \"data/interim/KB2018616.nc\")\n",
    "KH2018709_nc = os.path.join(parent_dir, \"data/interim/KH2018709.nc\")\n",
    "ascos_nc = os.path.join(parent_dir, \"data/interim/ascos_ds.nc\")\n",
    "\n",
    "arctic_ds = xr.open_dataset(arctic_mix)\n",
    "asbo_ds = xr.open_dataset(asbo_nc)\n",
    "mosaic_ds = xr.open_dataset(mosaic_nc)\n",
    "nice_ds = xr.open_dataset(nice_nc)\n",
    "HM_ds = xr.open_dataset(HM_nc)\n",
    "barneo2007_ds = xr.open_dataset(barneo2007_nc)\n",
    "barneo2008_ds = xr.open_dataset(barneo2008_nc)\n",
    "KB2018616_ds = xr.open_dataset(KB2018616_nc)\n",
    "KH2018709_ds = xr.open_dataset(KH2018709_nc)\n",
    "ascos_ds = xr.open_dataset(ascos_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "arctic_ds = arctic_ds.rename({\"longitude\": \"lon\", \"latitude\": \"lat\"})\n",
    "arctic_ds[\"latitude\"] = arctic_ds.lat\n",
    "arctic_ds[\"longitude\"] = arctic_ds.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "HM_ds = HM_ds.rename({\"time\": \"time_coor\"})\n",
    "HM_ds[\"time\"] = HM_ds.time_coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bathymetry dataset\n",
    "GEBCO_ds = os.path.join(parent_dir, \"data/external/GEBCO/gebco_2022_n80.0_s63.0_w-170.0_e-130.0.nc\")\n",
    "bathy_ds = xr.open_dataset(GEBCO_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea ice fraction data\n",
    "SI_HadISST = os.path.join(parent_dir, \"data/external/SI-area/HadISST_ice.nc\")\n",
    "Hadi_SI = xr.open_dataset(SI_HadISST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all features and combine all datasets into one dataframe\n",
    "The features and the plots are explained below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add variables of the cruise name\n",
    "arctic_ds[\"cruise\"] = \"ArcticMix\"\n",
    "nice_ds[\"cruise\"] = \"NICE-2015\"\n",
    "mosaic_ds[\"cruise\"] = \"Mosaic\"\n",
    "HM_ds[\"cruise\"] = \"Haakon Mosby\"\n",
    "barneo2007_ds[\"cruise\"] = \"IPY Barneo 2007\"\n",
    "barneo2008_ds[\"cruise\"] = \"IPY Barneo 2008\"\n",
    "KB2018616_ds[\"cruise\"] = \"Nansen Legacy 2018\"\n",
    "KH2018709_ds[\"cruise\"] = \"Nansen Legacy 2019\"\n",
    "ascos_ds[\"cruise\"] = \"ASCOS\"\n",
    "\n",
    "# asbo cruise name already assigned in preprocessing\n",
    "# asbo_ds[\"cruise\"] = \"ASBO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "asbo_ds[\"log_eps\"] =  np.log10(asbo_ds.eps)\n",
    "arctic_ds[\"log_eps\"] =  np.log10(arctic_ds.eps)\n",
    "nice_ds[\"log_eps\"] =  np.log10(nice_ds.eps)\n",
    "# mosaic already includes eps\n",
    "mosaic_ds[\"log_eps\"] =  (mosaic_ds.eps)\n",
    "HM_ds[\"log_eps\"] =  np.log10(HM_ds.eps)\n",
    "barneo2007_ds[\"log_eps\"] =  np.log10(barneo2007_ds.eps)\n",
    "barneo2008_ds[\"log_eps\"] =  np.log10(barneo2008_ds.eps)\n",
    "KB2018616_ds[\"log_eps\"] =  np.log10(KB2018616_ds.eps)\n",
    "KH2018709_ds[\"log_eps\"] =  np.log10(KH2018709_ds.eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"depth\", \"profile\", \"cruise\", \"latitude\", \"longitude\", \"S\", \"T\", \"log_eps\", \"log_N2\", \"dTdz\", \"dSdz\", \"hab\", \"Tu\", \"Tu_label\", \"time\", \"Rsubrho\", \"sea_ice_concentration\", \"MLDJ\", \"MLDI\", \"time\", \"seasonal_sin\", \"rho\", \"drhodz\"]\n",
    "# selected_columns = [\"depth\", \"profile\", \"latitude\", \"longitude\", \"P\", \"S\", \"T\", \"Tu\", \"kappa\", \"log_N2\", \"log_kappa\", \"log_eps\", \"dTdz\", \"dSdz\", \"eps\", \"cruise\", \"hab\", \"Tu_label\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_ds = processing_functions(nice_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "nice_df = nice_ds.to_dataframe().reset_index()\n",
    "nice_df.to_pickle(os.path.join(parent_dir, \"data/interim/nice_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_ds = processing_functions(mosaic_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "mosaic_df = mosaic_ds.to_dataframe().reset_index()\n",
    "mosaic_df.to_pickle(os.path.join(parent_dir, \"data/interim/mosaic_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "HM_ds = processing_functions(HM_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "HM_df = HM_ds.to_dataframe().reset_index()\n",
    "HM_df.to_pickle(os.path.join(parent_dir, \"data/interim/HM_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"depth\", \"profile\", \"cruise\", \"latitude\", \"longitude\", \"S\", \"T\", \"log_eps\", \"log_N2\", \"dTdz\", \"dSdz\", \"hab\", \"Tu\", \"Tu_label\", \"time\", \"Rsubrho\", \"sea_ice_concentration\", \"MLDJ\", \"MLDI\", \"time\", \"rho\", \"drhodz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "asbo_ds = processing_functions(asbo_ds, selected_columns, Hadi_SI, bathy_ds, ASBO=True)\n",
    "\n",
    "rho = asbo_ds['rho'].values\n",
    "S = asbo_ds['S'].values\n",
    "T = asbo_ds['T'].values\n",
    "\n",
    "# Calculate the vertical gradients of potential density\n",
    "drhodS = np.diff(rho, axis=0) / np.diff(S, axis=0)[:, :]\n",
    "drhodT = np.diff(rho, axis=0) / np.diff(T, axis=0)[:, :]\n",
    "\n",
    "# Add NaN values at the end of each depth\n",
    "drhodS = np.concatenate((drhodS, np.nan*np.ones((1, drhodS.shape[1]))), axis=0)\n",
    "drhodT = np.concatenate((drhodT, np.nan*np.ones((1, drhodT.shape[1]))), axis=0)\n",
    "\n",
    "# Calculate the density ratio\n",
    "Rho_ratio = drhodS / drhodT\n",
    "\n",
    "# Assign Rho_ratio to a new variable in the dataset\n",
    "asbo_ds[\"Rsubrho\"] = ((\"depth\", \"profile\"), Rho_ratio)\n",
    "asbo_ds = seasonal_sin(asbo_ds)\n",
    "\n",
    "# Assuming you have the salinity (S), temperature (T), and depth values\n",
    "S = asbo_ds['S'].values\n",
    "T = asbo_ds['T'].values\n",
    "depth = asbo_ds['depth'].values\n",
    "\n",
    "# Create a sorting index based on NaN values in temperature for each profile\n",
    "sort_indices = np.argsort(np.isnan(T), axis=0)\n",
    "\n",
    "# Initialize sorted_S and sorted_T arrays\n",
    "sorted_S = np.empty_like(S)\n",
    "sorted_T = np.empty_like(T)\n",
    "\n",
    "# Loop through each profile and sort the salinity and temperature values along the depth dimension\n",
    "for profile in range(S.shape[1]):\n",
    "    sorted_S[:, profile] = np.take(S[:, profile], sort_indices[:, profile])\n",
    "    sorted_T[:, profile] = np.take(T[:, profile], sort_indices[:, profile])\n",
    "\n",
    "# Sort the depth array using the sorting index\n",
    "sorted_depth = np.take(depth, sort_indices, axis=0)\n",
    "\n",
    "# Calculate the potential density using sorted salinity and temperature\n",
    "rho = gsw.rho(sorted_S, sorted_T, 0)\n",
    "\n",
    "# Calculate the vertical gradient of sorted potential density\n",
    "drhodz = np.diff(rho, axis=0) / np.diff(sorted_depth, axis=0)\n",
    "\n",
    "# Calculate the second vertical derivative of sorted potential density\n",
    "d2rhodz2 = np.diff(drhodz, axis=0) / np.diff(sorted_depth[:-1], axis=0)\n",
    "\n",
    "# Calculate the background buoyancy frequency\n",
    "g = 9.81  # acceleration due to gravity (m/s^2)\n",
    "# Add NaN values for the first and last depth level of rho\n",
    "# rho = np.concatenate(([np.nan], rho, [np.nan]))\n",
    "N2_bg = (g / rho[1:-1]) * d2rhodz2\n",
    "\n",
    "# Add NaN values for the first and last depth level of N2_bg\n",
    "nan_array = np.empty((1,) + N2_bg.shape[1:])\n",
    "nan_array[:] = np.nan\n",
    "N2_bg = np.concatenate((nan_array, N2_bg, nan_array), axis=0)\n",
    "\n",
    "# Assign log of background buoyancy frequency to a new variable in the dataset\n",
    "asbo_ds[\"log_N2\"] = ((\"depth\", \"profile\"), np.log(N2_bg))\n",
    "\n",
    "\n",
    "asbo_df = asbo_ds.to_dataframe().reset_index()\n",
    "\n",
    "# Different way of calculating N2 that does not generate as many NaNs\n",
    "# formula from https://www.sciencedirect.com/book/9780127329512/atmospheric-science\n",
    "# g = 9.81 # gravitational acceleration\n",
    "# asbo_df[\"N2\"] = ((g/asbo_df[\"rho\"]) * asbo_df[\"drhodz\"])**0.5\n",
    "# asbo_df[\"log_N2\"] = np.log10(asbo_df[\"N2\"])\n",
    "\n",
    "# Calculate the Turner angle\n",
    "asbo_df[\"Tu\"] = np.arctan(asbo_df[\"dSdz\"] / asbo_df[\"dTdz\"])\n",
    "\n",
    "\n",
    "asbo_df.to_pickle(os.path.join(parent_dir, \"data/interim/asbo_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "barneo2007_ds = processing_functions(barneo2007_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "barneo2007_df = barneo2007_ds.to_dataframe().reset_index()\n",
    "barneo2007_df.to_pickle(os.path.join(parent_dir, \"data/interim/barneo2007_df.pkl\"))\n",
    "barneo2008_df = processing_functions(barneo2008_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "barneo2008_df = barneo2008_ds.to_dataframe().reset_index()\n",
    "barneo2008_df.to_pickle(os.path.join(parent_dir, \"data/interim/barneo2008_df.pkl\"))\n",
    "\n",
    "KB2018616_ds = processing_functions(KB2018616_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "KB2018616_df = KB2018616_ds.to_dataframe().reset_index()\n",
    "KB2018616_df.to_pickle(os.path.join(parent_dir, \"data/interim/KB2018616_df.pkl\"))\n",
    "KH2018709_ds = processing_functions(KH2018709_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "KH2018709_df = KH2018709_ds.to_dataframe().reset_index()\n",
    "KH2018709_df.to_pickle(os.path.join(parent_dir, \"data/interim/KH2018709_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascos_ds = processing_functions(ascos_ds, selected_columns, Hadi_SI, bathy_ds)\n",
    "ascos_df = ascos_ds.to_dataframe().reset_index()\n",
    "ascos_df.to_pickle(os.path.join(parent_dir, \"data/interim/ascos_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_ds[\"sea_ice_concentration\"] = 0\n",
    "arctic_ds = processing_functions(arctic_ds, selected_columns, Hadi_SI, bathy_ds, True)\n",
    "arctic_df = arctic_ds.to_dataframe().reset_index()\n",
    "arctic_df.to_pickle(os.path.join(parent_dir, \"data/interim/arctic_df.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open saved dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/arctic_df.pkl\"))\n",
    "nice_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/nice_df.pkl\"))\n",
    "mosaic_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/mosaic_df.pkl\"))\n",
    "ascos_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/ascos_df.pkl\"))\n",
    "asbo_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/asbo_df.pkl\"))\n",
    "HM_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/HM_df.pkl\"))\n",
    "barneo2007_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/barneo2007_df.pkl\"))\n",
    "barneo2008_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/barneo2008_df.pkl\"))\n",
    "KB2018616_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/KB2018616_df.pkl\"))\n",
    "KH2018709_df = pd.read_pickle(os.path.join(parent_dir, \"data/interim/KH2018709_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([nice_df,arctic_df, mosaic_df, HM_df, asbo_df, barneo2007_df, barneo2008_df, KB2018616_df, KH2018709_df, ascos_df])\n",
    "combined_nona = combined_df.dropna()\n",
    "combined_nona.to_pickle(os.path.join(parent_dir, \"data/processed/ml_ready/2706_ML.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [nice_df,arctic_df, mosaic_df, HM_df, asbo_df, barneo2007_df, barneo2008_df, KB2018616_df, KH2018709_df, ascos_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to add a seasonal sine feature to a DataFrame\n",
    "def add_seasonal_sin_feature_to_df(df, time_column='time'):\n",
    "    # Extract the datetime array\n",
    "    datetime_array = pd.to_datetime(df[time_column])\n",
    "\n",
    "    # Extract the month and day from the datetime array\n",
    "    months = datetime_array.dt.month\n",
    "    days = datetime_array.dt.day\n",
    "\n",
    "    # Convert month and day to radians\n",
    "    month_radians = 2 * np.pi * (months - 1) / 12\n",
    "    day_radians = 2 * np.pi * (days - 1) / 31\n",
    "    \n",
    "    # Create seasonal sine feature\n",
    "    seasonal_sin = np.sin(month_radians + day_radians)\n",
    "\n",
    "    # Determine the season based on the month (0 = Winter, 1 = Spring, 2 = Summer, 3 = Autumn)\n",
    "    season = (months % 12) // 3\n",
    "\n",
    "    # Add seasonal sine and season features to the DataFrame\n",
    "    df['seasonal_sin'] = seasonal_sin\n",
    "    df['season'] = season\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"depth\", \"profile\", \"cruise\", \"latitude\", \"longitude\", \"S\", \"T\", \"log_eps\", \"log_N2\", \"dTdz\", \"dSdz\", \"hab\", \"Tu\", \"Tu_label\", \"Rsubrho\", \"sea_ice_concentration\", \"MLDJ\", \"MLDI\"]\n",
    "selected_columns_time = [\"depth\", \"profile\", \"cruise\", \"latitude\", \"longitude\", \"S\", \"T\", \"log_eps\", \"log_N2\", \"dTdz\", \"dSdz\", \"hab\", \"Tu\", \"Tu_label\", \"Rsubrho\", \"sea_ice_concentration\", \"MLDJ\", \"MLDI\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns from each DataFrame and concatenate thems\n",
    "combined_df_time = pd.concat([df[selected_columns_time] for df in dfs])\n",
    "\n",
    "# Convert 'inf' and '-inf' to 'NaN'\n",
    "combined_df_time = combined_df_time.replace([np.inf, -np.inf], np.nan)\n",
    "combined_df_time = add_seasonal_sin_feature_to_df(combined_df_time)\n",
    "\n",
    "combined_nona_time = combined_df_time.dropna()\n",
    "combined_nona_time.to_pickle(os.path.join(parent_dir, \"data/processed/ml_ready/1710_time.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/Lisanne/Documents/AI4ER/Mres/ArcticTurbulence/data/processed/ml_ready/1906_time.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save data using joblib\n",
    "joblib.dump(combined_nona_time, os.path.join(parent_dir, \"data/processed/ml_ready/1906_time.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(parent_dir, \"data/processed/ml_ready/1906_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_nona_time.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallo = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using joblib\n",
    "loaded_data = joblib.load(os.path.join(parent_dir, \"data/processed/ml_ready/1906_time.sav\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('gtc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e5b626aaea40ab619dc6757164911a8804e7edc5ad4b11453f28dfc67531fa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
